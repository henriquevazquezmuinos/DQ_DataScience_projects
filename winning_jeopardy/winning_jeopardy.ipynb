{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Winning Jeopardy\n",
    "In this project, we will work with a dataset of Jeopardy questions to figure out some patterns in the questions that could help you win.\n",
    "\n",
    "The dataset is named jeopardy.csv, and contains 20000 rows from the beginning of a full dataset of Jeopardy questions, which you can download [here](https://www.reddit.com/r/datasets/comments/1uyd0t/200000_jeopardy_questions_in_a_json_file/).\n",
    "\n",
    "Each row in the dataset represents a single question on a single episode of Jeopardy. Here are explanations of each column:\n",
    "\n",
    "* Show Number -- the Jeopardy episode number of the show this question was in.\n",
    "* Air Date -- the date the episode aired.\n",
    "* Round -- the round of Jeopardy that the question was asked in. Jeopardy has several rounds as each episode progresses.\n",
    "* Category -- the category of the question.\n",
    "* Value -- the number of dollars answering the question correctly is worth.\n",
    "* Question -- the text of the question.\n",
    "* Answer -- the text of the answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and  clean the data\n",
    "We perform the following operations:\n",
    "* Load the data\n",
    "* Rename columns by setting to lowercase and substituting spaces by underscores\n",
    "* Convert Value to float removing the $ symbols\n",
    "* Convert Air Date to datetime\n",
    "* Normalize text in Questions and Answers: send to lowercase and remove punctuation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['show_number', 'air_date', 'round', 'category', 'value', 'question',\n",
       "       'answer'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the data\n",
    "jeopardy = pd.read_csv('jeopardy.csv')\n",
    "# Rename the columns\n",
    "dic_col = {col:re.sub(r'\\s+','_', col.strip()).lower() for col in jeopardy.columns}\n",
    "jeopardy.rename(columns=dic_col, inplace=True)\n",
    "jeopardy.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    200\n",
       "1    200\n",
       "2    200\n",
       "3    200\n",
       "4    200\n",
       "Name: clean_value, dtype: int64"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert the value column to float (in dollars). There are None values, \n",
    "# we send them to $0 instead. Assign the values to cleaned_value\n",
    "jeopardy['clean_value'] = jeopardy['value'].str.replace(r'None','$0')\n",
    "jeopardy['clean_value'] = jeopardy['clean_value'].str.replace(r'$','').str.replace(r',','')\n",
    "jeopardy['clean_value'] = pd.to_numeric(jeopardy['clean_value'])\n",
    "\n",
    "jeopardy['clean_value'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 19999 entries, 0 to 19998\n",
      "Data columns (total 8 columns):\n",
      "show_number    19999 non-null int64\n",
      "air_date       19999 non-null datetime64[ns]\n",
      "round          19999 non-null object\n",
      "category       19999 non-null object\n",
      "value          19999 non-null object\n",
      "question       19999 non-null object\n",
      "answer         19999 non-null object\n",
      "clean_value    19999 non-null int64\n",
      "dtypes: datetime64[ns](1), int64(2), object(5)\n",
      "memory usage: 1.2+ MB\n"
     ]
    }
   ],
   "source": [
    "# Convert air_date from string to datetime\n",
    "jeopardy['air_date'] = pd.to_datetime(jeopardy['air_date'])\n",
    "jeopardy.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>show_number</th>\n",
       "      <th>air_date</th>\n",
       "      <th>round</th>\n",
       "      <th>category</th>\n",
       "      <th>value</th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "      <th>clean_value</th>\n",
       "      <th>clean_question</th>\n",
       "      <th>clean_answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4680</td>\n",
       "      <td>2004-12-31</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>HISTORY</td>\n",
       "      <td>$200</td>\n",
       "      <td>For the last 8 years of his life, Galileo was ...</td>\n",
       "      <td>Copernicus</td>\n",
       "      <td>200</td>\n",
       "      <td>for the last 8 years of his life galileo was u...</td>\n",
       "      <td>copernicus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4680</td>\n",
       "      <td>2004-12-31</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>ESPN's TOP 10 ALL-TIME ATHLETES</td>\n",
       "      <td>$200</td>\n",
       "      <td>No. 2: 1912 Olympian; football star at Carlisl...</td>\n",
       "      <td>Jim Thorpe</td>\n",
       "      <td>200</td>\n",
       "      <td>no 2 1912 olympian football star at carlisle i...</td>\n",
       "      <td>jim thorpe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4680</td>\n",
       "      <td>2004-12-31</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>EVERYBODY TALKS ABOUT IT...</td>\n",
       "      <td>$200</td>\n",
       "      <td>The city of Yuma in this state has a record av...</td>\n",
       "      <td>Arizona</td>\n",
       "      <td>200</td>\n",
       "      <td>the city of yuma in this state has a record av...</td>\n",
       "      <td>arizona</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4680</td>\n",
       "      <td>2004-12-31</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>THE COMPANY LINE</td>\n",
       "      <td>$200</td>\n",
       "      <td>In 1963, live on \"The Art Linkletter Show\", th...</td>\n",
       "      <td>McDonald's</td>\n",
       "      <td>200</td>\n",
       "      <td>in 1963 live on the art linkletter show this c...</td>\n",
       "      <td>mcdonalds</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4680</td>\n",
       "      <td>2004-12-31</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>EPITAPHS &amp; TRIBUTES</td>\n",
       "      <td>$200</td>\n",
       "      <td>Signer of the Dec. of Indep., framer of the Co...</td>\n",
       "      <td>John Adams</td>\n",
       "      <td>200</td>\n",
       "      <td>signer of the dec of indep framer of the const...</td>\n",
       "      <td>john adams</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   show_number   air_date      round                         category value  \\\n",
       "0         4680 2004-12-31  Jeopardy!                          HISTORY  $200   \n",
       "1         4680 2004-12-31  Jeopardy!  ESPN's TOP 10 ALL-TIME ATHLETES  $200   \n",
       "2         4680 2004-12-31  Jeopardy!      EVERYBODY TALKS ABOUT IT...  $200   \n",
       "3         4680 2004-12-31  Jeopardy!                 THE COMPANY LINE  $200   \n",
       "4         4680 2004-12-31  Jeopardy!              EPITAPHS & TRIBUTES  $200   \n",
       "\n",
       "                                            question      answer  clean_value  \\\n",
       "0  For the last 8 years of his life, Galileo was ...  Copernicus          200   \n",
       "1  No. 2: 1912 Olympian; football star at Carlisl...  Jim Thorpe          200   \n",
       "2  The city of Yuma in this state has a record av...     Arizona          200   \n",
       "3  In 1963, live on \"The Art Linkletter Show\", th...  McDonald's          200   \n",
       "4  Signer of the Dec. of Indep., framer of the Co...  John Adams          200   \n",
       "\n",
       "                                      clean_question clean_answer  \n",
       "0  for the last 8 years of his life galileo was u...   copernicus  \n",
       "1  no 2 1912 olympian football star at carlisle i...   jim thorpe  \n",
       "2  the city of yuma in this state has a record av...      arizona  \n",
       "3  in 1963 live on the art linkletter show this c...    mcdonalds  \n",
       "4  signer of the dec of indep framer of the const...   john adams  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Send answers to lower case and remove punctuation\n",
    "def normalize_text(s):\n",
    "    snew = s.copy()\n",
    "    snew = snew.str.lower()\n",
    "    snew = snew.str.replace(r'[^\\w\\s]','')\n",
    "    return snew\n",
    "\n",
    "# Clean question and answer columns, and assign to \n",
    "# clear_question and clear_answer columns\n",
    "jeopardy['clean_question'] = normalize_text(jeopardy['question'])\n",
    "jeopardy['clean_answer'] = normalize_text(jeopardy['answer'])\n",
    "jeopardy.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyze the data\n",
    "We want to answer the following questions:\n",
    "* How often the answer is deducible from the question (Overlap bbetween question and answer).\n",
    "* How often new questions are repeats of older questions (Overlap between old questions).\n",
    "\n",
    "We can answer the second question by seeing how often complex words (> 6 characters) reoccur. We can answer the first question by seeing how many times words in the answer also occur in the question. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overlap between questions and answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mean of answer_in_question: 0.057955758538287654\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.000000    0.876294\n",
       "0.500000    0.071254\n",
       "0.333333    0.024801\n",
       "0.250000    0.007200\n",
       "1.000000    0.006200\n",
       "0.666667    0.005350\n",
       "0.200000    0.003350\n",
       "0.400000    0.001150\n",
       "0.166667    0.001150\n",
       "0.142857    0.000950\n",
       "0.750000    0.000600\n",
       "0.125000    0.000350\n",
       "0.285714    0.000300\n",
       "0.600000    0.000300\n",
       "0.111111    0.000150\n",
       "0.428571    0.000150\n",
       "0.300000    0.000100\n",
       "0.800000    0.000100\n",
       "0.875000    0.000050\n",
       "0.100000    0.000050\n",
       "0.444444    0.000050\n",
       "0.133333    0.000050\n",
       "0.181818    0.000050\n",
       "Name: answer_in_question, dtype: float64"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def answer_question_match(s):\n",
    "    # split answer and question. We remove 'the' word from answers\n",
    "    split_answer = s['clean_answer'].replace('the', '').split()\n",
    "    split_question = s['clean_question'].split()\n",
    "    \n",
    "    # discard answers with length 0\n",
    "    if len(split_answer)==0:\n",
    "        return 0\n",
    "    # count the appearences of an answer word in the question\n",
    "    match_count = 0\n",
    "    for word in split_answer:\n",
    "        if word in split_question:\n",
    "            match_count += 1\n",
    "    # normalize the counts to the answer length\n",
    "    answer_in_question = match_count/len(split_answer)\n",
    "    return answer_in_question\n",
    "\n",
    "jeopardy['answer_in_question'] = jeopardy.apply(answer_question_match, axis=1)\n",
    "print('The mean of answer_in_question: {0}'.format(jeopardy['answer_in_question'].mean()))\n",
    "jeopardy['answer_in_question'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we see most of the times (88%) there is no overlap between the answer and the question. In a 7% there is 0.5 overlap and in a 2% there is 1/3 overlap. The mean overlap between answer in question is a 6%, rather small. Therefore we claim that it is not very helpful the text in the question to automatically deduce the answer, since the overlap is small."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overlap between questions through jeopardy history\n",
    "Here in our analysis we decide to reject words with length < 6, as they likely do not contain specific information regarding the question, i.e. they are not \"complex words\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>show_number</th>\n",
       "      <th>air_date</th>\n",
       "      <th>round</th>\n",
       "      <th>category</th>\n",
       "      <th>value</th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "      <th>clean_value</th>\n",
       "      <th>clean_question</th>\n",
       "      <th>clean_answer</th>\n",
       "      <th>answer_in_question</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19325</th>\n",
       "      <td>10</td>\n",
       "      <td>1984-09-21</td>\n",
       "      <td>Final Jeopardy!</td>\n",
       "      <td>U.S. PRESIDENTS</td>\n",
       "      <td>None</td>\n",
       "      <td>Adventurous 26th president, he was 1st to ride...</td>\n",
       "      <td>Theodore Roosevelt</td>\n",
       "      <td>0</td>\n",
       "      <td>adventurous 26th president he was 1st to ride ...</td>\n",
       "      <td>theodore roosevelt</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19285</th>\n",
       "      <td>10</td>\n",
       "      <td>1984-09-21</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>GEOGRAPHY</td>\n",
       "      <td>$300</td>\n",
       "      <td>8th most populous country in the world, this \"...</td>\n",
       "      <td>Bangladesh</td>\n",
       "      <td>300</td>\n",
       "      <td>8th most populous country in the world this be...</td>\n",
       "      <td>bangladesh</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19324</th>\n",
       "      <td>10</td>\n",
       "      <td>1984-09-21</td>\n",
       "      <td>Double Jeopardy!</td>\n",
       "      <td>TV TRIVIA</td>\n",
       "      <td>$1000</td>\n",
       "      <td>In court, he'd always make mincemeat of Hamilt...</td>\n",
       "      <td>Perry Mason</td>\n",
       "      <td>1000</td>\n",
       "      <td>in court hed always make mincemeat of hamilton...</td>\n",
       "      <td>perry mason</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19301</th>\n",
       "      <td>10</td>\n",
       "      <td>1984-09-21</td>\n",
       "      <td>Double Jeopardy!</td>\n",
       "      <td>LABOR UNIONS</td>\n",
       "      <td>$200</td>\n",
       "      <td>Notorious labor leader missing since '75</td>\n",
       "      <td>Jimmy Hoffa</td>\n",
       "      <td>200</td>\n",
       "      <td>notorious labor leader missing since 75</td>\n",
       "      <td>jimmy hoffa</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19302</th>\n",
       "      <td>10</td>\n",
       "      <td>1984-09-21</td>\n",
       "      <td>Double Jeopardy!</td>\n",
       "      <td>1789</td>\n",
       "      <td>$200</td>\n",
       "      <td>Washington proclaimed Nov. 26, 1789 this first...</td>\n",
       "      <td>Thanksgiving</td>\n",
       "      <td>200</td>\n",
       "      <td>washington proclaimed nov 26 1789 this first n...</td>\n",
       "      <td>thanksgiving</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       show_number   air_date             round         category  value  \\\n",
       "19325           10 1984-09-21   Final Jeopardy!  U.S. PRESIDENTS   None   \n",
       "19285           10 1984-09-21         Jeopardy!        GEOGRAPHY   $300   \n",
       "19324           10 1984-09-21  Double Jeopardy!        TV TRIVIA  $1000   \n",
       "19301           10 1984-09-21  Double Jeopardy!     LABOR UNIONS   $200   \n",
       "19302           10 1984-09-21  Double Jeopardy!             1789   $200   \n",
       "\n",
       "                                                question              answer  \\\n",
       "19325  Adventurous 26th president, he was 1st to ride...  Theodore Roosevelt   \n",
       "19285  8th most populous country in the world, this \"...          Bangladesh   \n",
       "19324  In court, he'd always make mincemeat of Hamilt...         Perry Mason   \n",
       "19301           Notorious labor leader missing since '75         Jimmy Hoffa   \n",
       "19302  Washington proclaimed Nov. 26, 1789 this first...        Thanksgiving   \n",
       "\n",
       "       clean_value                                     clean_question  \\\n",
       "19325            0  adventurous 26th president he was 1st to ride ...   \n",
       "19285          300  8th most populous country in the world this be...   \n",
       "19324         1000  in court hed always make mincemeat of hamilton...   \n",
       "19301          200            notorious labor leader missing since 75   \n",
       "19302          200  washington proclaimed nov 26 1789 this first n...   \n",
       "\n",
       "             clean_answer  answer_in_question  \n",
       "19325  theodore roosevelt                 0.0  \n",
       "19285          bangladesh                 0.0  \n",
       "19324         perry mason                 0.0  \n",
       "19301         jimmy hoffa                 0.0  \n",
       "19302        thanksgiving                 0.0  "
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We sort the dataframe by air_date chronologically from older to newer, \n",
    "# this way we see how the usage of terms repeats through time\n",
    "jeopardy = jeopardy.sort_values(by='air_date', ascending=True)\n",
    "jeopardy.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# iterate from older to newer questions keeping track of\n",
    "# the \"complex\" (length >= 6 characters) terms which repeat \n",
    "# we store the percentage of repeating terms comapared to older\n",
    "# appearences of the terms.\n",
    "question_overlap = []\n",
    "terms_used = set()\n",
    "for index, row in jeopardy.iterrows():\n",
    "    match_count = 0\n",
    "    # split question strings into words\n",
    "    split_question_raw = row['clean_question'].split()\n",
    "    split_question = []\n",
    "    for word in split_question_raw:\n",
    "        # descard words shorter than 6 and add word to terms_used\n",
    "        # if it was not there yet\n",
    "        if len(word) >= 6:\n",
    "            split_question.append(word)\n",
    "            if word in terms_used:\n",
    "                match_count += 1\n",
    "            else:\n",
    "                terms_used.add(word)\n",
    "    # append the normalized (divided by number oif words in the question) \n",
    "    # matches to question_overlap list. Neglect cases where length = 0.\n",
    "    if len(split_question)==0:\n",
    "        match_count = 0\n",
    "    else:\n",
    "        match_count = match_count/len(split_question)\n",
    "    question_overlap.append(match_count)\n",
    "jeopardy['question_overlap'] = pd.Series(question_overlap, index=jeopardy.index)     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of questions with less than 0,5 overlap: 17.6158807940397%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.000000    0.306215\n",
       "0.500000    0.110156\n",
       "0.666667    0.098505\n",
       "0.000000    0.079704\n",
       "0.750000    0.079004\n",
       "0.800000    0.062053\n",
       "0.600000    0.045802\n",
       "0.833333    0.040502\n",
       "0.333333    0.036652\n",
       "0.857143    0.022951\n",
       "Name: question_overlap, dtype: float64"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZEAAAEACAYAAAByG0uxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fcc83e2b7b8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "jeopardy['question_overlap'].plot.hist()\n",
    "less_half_overlap = (jeopardy['question_overlap']<0.5).sum()/jeopardy['question_overlap'].shape[0]\n",
    "print('Percentage of questions with less than 0,5 overlap: {0}%'.format(less_half_overlap*100))\n",
    "jeopardy['question_overlap'].value_counts(normalize=True).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that a 30% of the questions are identically repeated, whereas only a 17% of all the questions have less than a 0.5 overlap. We set as 0,5 overlap as the threshold to determine it to be a different question. Hence, we conclude that in geopardy the best way to prepare for competing is byu studying all the older questions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding out the words with the highest impact on the value\n",
    "Here now we proceed to estimate the probabilities of words in terms_used to appear, together with High or Low value of the question. The High/Low value category is defined as Value lower or equal/higher than ¤800.\n",
    "\n",
    "To determine which are the words that affect the most the value, we compute the chi-squared for a subset of words, and choose the ones with the highest ch-squared value associated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def classify_by_value(row):\n",
    "    if row['clean_value'] > 800:\n",
    "        value = 1\n",
    "    else :\n",
    "        value = 0\n",
    "    return value\n",
    "\n",
    "def word_counts_in_high_low_questions(word, df):\n",
    "    low_count = 0\n",
    "    high_count = 0\n",
    "    for index, row in df.iterrows():\n",
    "        # split question strings into words\n",
    "        split_question_raw = row['clean_question'].split()\n",
    "        if word in split_question_raw:\n",
    "            if row['high_value'] :\n",
    "                high_count += 1\n",
    "            else:\n",
    "                low_count += 1\n",
    "    return high_count, low_count\n",
    "\n",
    "# classify into high and low value the questions\n",
    "jeopardy['high_value'] = jeopardy.apply(classify_by_value,axis=1)\n",
    "\n",
    "# select 10 random words from terms_used\n",
    "comparison_terms = random.sample(terms_used, 100)\n",
    "\n",
    "# append the high/low_counts associated to each word to \n",
    "# the list observed_expected\n",
    "observed_expected = []\n",
    "for word in comparison_terms:\n",
    "    high_low_values = word_counts_in_high_low_questions(word, jeopardy)\n",
    "    observed_expected.append(high_low_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 1),\n",
       " (1, 12),\n",
       " (1, 0),\n",
       " (1, 4),\n",
       " (0, 1),\n",
       " (0, 1),\n",
       " (3, 16),\n",
       " (0, 1),\n",
       " (1, 0),\n",
       " (1, 1),\n",
       " (1, 3),\n",
       " (0, 2),\n",
       " (1, 0),\n",
       " (1, 0),\n",
       " (0, 1),\n",
       " (0, 1),\n",
       " (8, 9),\n",
       " (0, 1),\n",
       " (1, 4),\n",
       " (1, 0),\n",
       " (12, 44),\n",
       " (0, 1),\n",
       " (0, 1),\n",
       " (1, 0),\n",
       " (1, 1),\n",
       " (0, 1),\n",
       " (2, 3),\n",
       " (1, 0),\n",
       " (2, 8),\n",
       " (0, 1),\n",
       " (0, 1),\n",
       " (0, 1),\n",
       " (0, 1),\n",
       " (1, 0),\n",
       " (0, 1),\n",
       " (5, 19),\n",
       " (1, 0),\n",
       " (3, 8),\n",
       " (0, 1),\n",
       " (0, 1),\n",
       " (3, 3),\n",
       " (7, 13),\n",
       " (0, 1),\n",
       " (1, 1),\n",
       " (0, 1),\n",
       " (0, 1),\n",
       " (2, 2),\n",
       " (2, 2),\n",
       " (1, 0),\n",
       " (0, 2),\n",
       " (0, 1),\n",
       " (0, 1),\n",
       " (3, 5),\n",
       " (0, 1),\n",
       " (0, 4),\n",
       " (1, 0),\n",
       " (0, 1),\n",
       " (0, 1),\n",
       " (1, 0),\n",
       " (0, 1),\n",
       " (0, 1),\n",
       " (0, 1),\n",
       " (0, 1),\n",
       " (1, 1),\n",
       " (0, 1),\n",
       " (1, 0),\n",
       " (1, 0),\n",
       " (0, 1),\n",
       " (0, 1),\n",
       " (3, 3),\n",
       " (1, 0),\n",
       " (0, 1),\n",
       " (1, 0),\n",
       " (1, 0),\n",
       " (0, 4),\n",
       " (1, 0),\n",
       " (1, 0),\n",
       " (1, 1),\n",
       " (0, 1),\n",
       " (1, 0),\n",
       " (0, 1),\n",
       " (1, 0),\n",
       " (4, 10),\n",
       " (3, 9),\n",
       " (0, 1),\n",
       " (1, 0),\n",
       " (0, 1),\n",
       " (1, 1),\n",
       " (1, 0),\n",
       " (0, 2),\n",
       " (0, 1),\n",
       " (1, 1),\n",
       " (1, 4),\n",
       " (0, 1),\n",
       " (1, 2),\n",
       " (0, 2),\n",
       " (0, 1),\n",
       " (2, 1),\n",
       " (0, 1),\n",
       " (0, 1)]"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "observed_expected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import chisquare\n",
    "# Calculate the chi-squared associated to the distribution\n",
    "high_value_count = (jeopardy['high_value']==1).sum()\n",
    "low_value_count = (jeopardy['high_value']==0).sum()\n",
    "\n",
    "chi_squared = []\n",
    "for high_counts, low_counts in observed_expected:\n",
    "    total = high_counts + low_counts\n",
    "    total_prop = total/jeopardy.shape[0]\n",
    "    high_expected = total_prop*high_value_count \n",
    "    low_expected = total_prop*low_value_count\n",
    "    chisq, pval = chisquare([high_counts, low_counts], \n",
    "                            [high_expected, low_expected])\n",
    "    chi_squared.append(pval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    100.000000\n",
       "mean       0.411741\n",
       "std        0.214677\n",
       "min        0.093652\n",
       "25%        0.137886\n",
       "50%        0.526077\n",
       "75%        0.526077\n",
       "max        0.993398\n",
       "dtype: float64"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(chi_squared).describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we see, there is no statistically relevant relation between the random sample of words and the value of the question. Of course, in our case, most of the words are mentioned only once or twice in our dataset, and fir such low counts the chi-squared test is not relevant. We coul instead choose only words with a minimum of mentions in our dataset and repeat this test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusions\n",
    "In this project we analyzed the questions and answers from 20 years of the jeopardy quiz, and found out the following:\n",
    "* As much as 83% of the questions seem to repeat, or overlap with previous questions.\n",
    "* The overlap between questions and answers is rather small ~10%, and therefore we e"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
